- name: create a mount point for the data volume
  ansible.builtin.file:
    path: data/
    state: directory
    mode: '0755' 
- name: format the volume as ext4
  community.general.filesystem:
    dev: /dev/xvdf
    fstype: ext4
  become: true
- name: mount the filesystem
  become: true
  ansible.posix.mount:
    name: data
    src: /dev/xvdf
    fstype: ext4
    state: mounted 
  become: true
- name: change the owner back to ec2-user after mounting
  become: true
  ansible.builtin.file:
    path: data/
    state: directory
    mode: u+rwx,a+x
    owner: ec2-user
- name: Install yum packages
  become: true
  ansible.builtin.yum:
    name: "{{ packages }}"
  vars:
    packages:
    - python
    - python-pip
    - unzip
    - wget
- name: install this package from from git
  ansible.builtin.pip:
    name: git+https://github.com/jamespjh/EngineeringForDataAnalysisExamples.git
    state: forcereinstall
- name: install awscli
  ansible.builtin.pip:
    name: awscli
- name: Create temp folder for incomplete downloads on larger volume
  ansible.builtin.file:
    path: data/tmp
    state: directory
    mode: '0755'
- name: Create folder for clients to deposit their results
  ansible.builtin.file:
    path: results
    state: directory
    mode: '0755' 
- name: Set up the cluster key to allow clients to ssh to the host
  ansible.posix.authorized_key:
    user: ec2-user
    key: "{{lookup('file', '/Users/jamespjh/.ssh/cluster-key.pub') }}"
- name: Fetch the individual files 
# Need to point out that this is a faff cf cat targets |
# xargs -n1 wget but worth it for stability
# Or GNU parallel
  ansible.builtin.get_url:
    url:   "https://s3.eu-west-2.amazonaws.com/nineteenth-century-books/{{ item }}.zip"
    dest: "data/{{item}}.zip"
    tmp_dest: data/tmp
  loop: "{{targets}}"
  register: monitor
# - name: unzip the files (top level of zipping only)
# #https://docs.ansible.com/ansible/latest/collections/ansible/builtin/unarchive_module.html
# # Why use this rather than a shell command? Save time - no need to unzip twice and ansible's task detects this
#   ansible.builtin.unarchive:
#     src: "data/{{item}}.zip"
#     dest: data
#     remote_src: yes
# # loop: "{{targets}}"
# - name: get the list of objects to put to S3
#   ansible.builtin.find:
#     paths: data/1850_1859/
#     recurse: no
#   register: objects
# - name: put the individual zip files to S3 with ansible task
#   amazon.aws.s3_object:
#     bucket: data-bucket-books-example
#     object: "{{item | basename}}"
#     src: "{{item}}"
#     mode: put
#     permission: [] # We're using AWS bucket policies not ACLs
#   loop: "{{objects.files | map(attribute='path')}}"
#   async: 1200
#   poll: 0
#   register: async_data
# - name: check the data copies have finished
#   async_status:
#     jid: "{{ item.ansible_job_id }}"
#   register: job_result
#   until: job_result.finished
#   retries: 100
#   delay: 2
#   loop: "{{async_data.results}}"
- name: put the individual zip files to S3
  # Doing it this way is not idempotent, but worth comparing fast!
  ansible.builtin.shell: "aws s3 sync data/1850_1859 s3://data-bucket-books-example"
    
